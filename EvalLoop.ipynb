{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mask R-CNN - Inspect Trained Model\n",
    "\n",
    "Code and visualizations to test, debug, and evaluate the Mask R-CNN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Mask R-CNN\n",
    "Configurations and data loading code for MS COCO.\n",
    "\n",
    "Copyright (c) 2017 Matterport, Inc.\n",
    "Licensed under the MIT License (see LICENSE for details)\n",
    "Written by Waleed Abdulla\n",
    "\n",
    "------------------------------------------------------------\n",
    "\n",
    "Usage: import the module (see Jupyter notebooks for examples), or run from\n",
    "       the command line as such:\n",
    "\n",
    "    # Train a new model starting from pre-trained COCO weights\n",
    "    python3 coco.py train --dataset=/path/to/coco/ --model=coco\n",
    "\n",
    "    # Train a new model starting from ImageNet weights. Also auto download COCO dataset\n",
    "    python3 raspberriesV1.py train --dataset=/host/Mask_RCNN/datasets/raspberry/ --model=imagenet \n",
    "\n",
    "    # Continue training a model that you had trained earlier\n",
    "    python3 raspberriesV1.py train --dataset=/host/Mask_RCNN/datasets/raspberry/ --model=/host/Mask_RCNN/logs/raspberry20180824T0517/mask_rcnn_raspberry_0135.h5\n",
    "\n",
    "    # Continue training the last model you trained\n",
    "    python3 coco.py train --dataset=/path/to/coco/ --model=last\n",
    "\n",
    "    # Run COCO evaluatoin on the last model you trained\n",
    "    python3 raspberriesV1.py evaluate --dataset=/host/Mask_RCNN/datasets/raspberry/ --model=/host/Mask_RCNN/logs/raspberry20180824T0517/mask_rcnn_raspberry_0135.h5 --limit=100\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import imgaug  # https://github.com/aleju/imgaug (pip3 install imgaug)\n",
    "\n",
    "# Download and install the Python COCO tools from https://github.com/waleedka/coco\n",
    "# That's a fork from the original https://github.com/pdollar/coco with a bug\n",
    "# fix for Python 3.\n",
    "# I submitted a pull request https://github.com/cocodataset/cocoapi/pull/50\n",
    "# If the PR is merged then use the original repo.\n",
    "# Note: Edit PythonAPI/Makefile and replace \"python\" with \"python3\".\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import json as js\n",
    "import numpy as np\n",
    "import skimage.draw\n",
    "import imgaug  # https://github.com/aleju/imgaug (pip3 install imgaug)\n",
    "\n",
    "# Download and install the Python COCO tools from https://github.com/waleedka/coco\n",
    "# That's a fork from the original https://github.com/pdollar/coco with a bug\n",
    "# fix for Python 3.\n",
    "# I submitted a pull request https://github.com/cocodataset/cocoapi/pull/50\n",
    "# If the PR is merged then use the original repo.\n",
    "# Note: Edit PythonAPI/Makefile and replace \"python\" with \"python3\".\n",
    "from pycocotools.coco import COCO\n",
    "from pycocotools.cocoeval import COCOeval\n",
    "from pycocotools import mask as maskUtils\n",
    "\n",
    "import zipfile\n",
    "import urllib.request\n",
    "import shutil\n",
    "\n",
    "# Root directory of the project\n",
    "ROOT_DIR = os.path.abspath(\"../../\")\n",
    "\n",
    "\n",
    "# Import Mask RCNN\n",
    "sys.path.append(ROOT_DIR)  # To find local version of the library\n",
    "from mrcnn.config import Config\n",
    "from mrcnn import model as modellib, utils\n",
    "\n",
    "# Path to trained weights file\n",
    "COCO_MODEL_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_coco.h5\")\n",
    "\n",
    "# Directory to save logs and model checkpoints, if not provided\n",
    "# through the command line argument --logs\n",
    "DEFAULT_LOGS_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
    "\n",
    "\n",
    "\n",
    "############################################################\n",
    "#  Configurations\n",
    "############################################################\n",
    "\n",
    "\n",
    "class RaspberryConfig(Config):\n",
    "    # Give the configuration a recognizable name\n",
    "    NAME = \"raspberry\"\n",
    "\n",
    "    # We use a GPU with 12GB memory, which can fit two images.\n",
    "    # Adjust down if you use a smaller GPU.\n",
    "    IMAGES_PER_GPU = 1\n",
    "\n",
    "    # Uncomment to train on 8 GPUs (default is 1)\n",
    "    GPU_COUNT = 1\n",
    "    DEVICE = \"/gpu:0\"\n",
    "    \n",
    "    #USE_MINI_MASK = False\n",
    "    \n",
    "    # Learning rate and momentum\n",
    "    # The Mask RCNN paper uses lr=0.02, but on TensorFlow it causes\n",
    "    # weights to explode. Likely due to differences in optimizer\n",
    "    # implementation.\n",
    "    LEARNING_RATE = 0.001 # Default is 0.001\n",
    "    LEARNING_MOMENTUM = 0.9 # Default is 0.9\n",
    "    \n",
    "    # Weight decay regularization\n",
    "    #WEIGHT_DECAY = 0.0001\n",
    "\n",
    "    # Number of classes (including background) \n",
    "    NUM_CLASSES = 1 + 3  \n",
    "    \n",
    "    #DETECTION_MIN_CONFIDENCE = 0.7  #tried 0.9, 0.7\n",
    "    \n",
    "    # The strides of each layer of the FPN Pyramid. These values\n",
    "    # are based on a Resnet101 backbone.\n",
    "    #BACKBONE_STRIDES = [13, 19, 25, 32, 38] #2, 4, 8, 16, 32\n",
    "    \n",
    "    # Non-maximum suppression threshold for detection\n",
    "    #DETECTION_NMS_THRESHOLD = 0.2  #0.3\n",
    "    \n",
    "    # Non-max suppression threshold to filter RPN proposals.\n",
    "    # You can increase this during training to generate more propsals.\n",
    "    RPN_NMS_THRESHOLD = 0.9  #0.7\n",
    "    \n",
    "    # Number of ROIs per image to feed to classifier/mask heads\n",
    "    # The Mask RCNN paper uses 512 but often the RPN doesn't generate\n",
    "    # enough positive proposals to fill this and keep a positive:negative\n",
    "    # ratio of 1:3. You can increase the number of proposals by adjusting\n",
    "    # the RPN NMS threshold.\n",
    "    TRAIN_ROIS_PER_IMAGE = 40\n",
    "    \n",
    "    STEPS_PER_EPOCH = 200 #20\n",
    "    \n",
    "    VALIDATION_STEPS = 20  #10\n",
    "    \n",
    "    BACKBONE = \"resnet50\"\n",
    "    \n",
    "    #MAX_GT_INSTANCES = 7\n",
    "    #DETECTION_MAX_INSTANCES = 12\n",
    "    \n",
    "    # Length of square anchor side in pixels\n",
    "    #RPN_ANCHOR_SCALES = (208, 304, 400, 512, 608)  #32, 64,128,256,512\n",
    "    \n",
    "    # Ratios of anchors at each cell (width/height)\n",
    "    # A value of 1 represents a square anchor, and 0.5 is a wide anchor\n",
    "    RPN_ANCHOR_RATIOS = [0.75, 1, 1.5]\n",
    "    \n",
    "    # Anchor stride\n",
    "    # If 1 then anchors are created for each cell in the backbone feature map.\n",
    "    # If 2, then anchors are created for every other cell, and so on.\n",
    "    RPN_ANCHOR_STRIDE = 2\n",
    "\n",
    "    \n",
    "    #IMAGE_RESIZE_MODE = \"square\"\n",
    "    #IMAGE_MIN_DIM = 576\n",
    "    #IMAGE_MAX_DIM = 1024\n",
    "    #IMAGE_MIN_SCALE = 0\n",
    "    \n",
    "    GRADIENT_CLIP_NORM = 5.0  #tried 5, 10, 15 default:5\n",
    "    \n",
    "    # Loss weights for more precise optimization.\n",
    "    # Can be used for R-CNN training setup.\n",
    "    LOSS_WEIGHTS = {\n",
    "        \"rpn_class_loss\": 1.0,\n",
    "        \"rpn_bbox_loss\": 1.0,\n",
    "        \"mrcnn_class_loss\": 1.0,\n",
    "        \"mrcnn_bbox_loss\": 1.0,\n",
    "        \"mrcnn_mask_loss\": 1.0\n",
    "    }\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "############################################################\n",
    "#  Dataset\n",
    "############################################################\n",
    "\n",
    "class RaspberryDataset(utils.Dataset):\n",
    "    def load_raspberry(self, dataset_dir, subset):\n",
    "        \"\"\"Load a subset of the COCO dataset.\n",
    "        \"\"\"\n",
    "        self.add_class(\"object\", 1, \"raspberry_1\")\n",
    "        self.add_class(\"object\", 2, \"raspberry_2\")\n",
    "        self.add_class(\"object\", 3, \"raspberry_3\")\n",
    "        #self.add_class(\"object\", 4, \"raspberry_4\")\n",
    "        \n",
    "        # Train or validation dataset?\n",
    "        assert subset in [\"train\", \"val\", \"test\"]\n",
    "        dataset_dir = os.path.join(dataset_dir, subset)\n",
    "       \n",
    "        annotations = js.load(open(os.path.join(dataset_dir, \"via_region_data.json\")))\n",
    "        annotations = list(annotations.values())  # don't need the dict keys\n",
    "\n",
    "        # The VIA tool saves images in the JSON even if they don't have any\n",
    "        # annotations. Skip unannotated images.\n",
    "        annotations = [a for a in annotations if a['regions']]\n",
    "\n",
    "        # Add images\n",
    "        for a in annotations:\n",
    "            # Get the x, y coordinaets of points of the polygons that make up\n",
    "            # the outline of each object instance. There are stores in the\n",
    "            # shape_attributes (see json format above)\n",
    "            polygons = [r['shape_attributes'] for r in a['regions'].values()]\n",
    "            objects = [s['region_attributes'] for s in a['regions'].values()]\n",
    "            num_ids = [int(n['object']) for n in objects]\n",
    "            \n",
    "            # load_mask() needs the image size to convert polygons to masks.\n",
    "            # Unfortunately, VIA doesn't include it in JSON, so we must read\n",
    "            # the image. This is only managable since the dataset is tiny.\n",
    "            image_path = os.path.join(dataset_dir, a['filename'])\n",
    "            image = skimage.io.imread(image_path)\n",
    "            height, width = image.shape[:2]\n",
    "\n",
    "            self.add_image(\n",
    "                \"object\",\n",
    "                image_id=a['filename'],  # use file name as a unique image id\n",
    "                path=image_path,\n",
    "                width=width, height=height,\n",
    "                polygons=polygons,\n",
    "                num_ids=num_ids)\n",
    "            \n",
    "\n",
    "    def load_mask(self, image_id):\n",
    "        \"\"\"Generate instance masks for an image.\n",
    "       Returns:\n",
    "        masks: A bool array of shape [height, width, instance count] with\n",
    "            one mask per instance.\n",
    "        class_ids: a 1D array of class IDs of the instance masks.\n",
    "        \"\"\"\n",
    "        # If not a balloon dataset image, delegate to parent class.\n",
    "        info = self.image_info[image_id]\n",
    "        if info[\"source\"] != \"object\":\n",
    "            return super(self.__class__, self).load_mask(image_id)\n",
    "\n",
    "        num_ids = info['num_ids']\n",
    "        # Convert polygons to a bitmap mask of shape\n",
    "        # [height, width, instance_count]\n",
    "        mask = np.zeros([info[\"height\"], info[\"width\"], len(info[\"polygons\"])],\n",
    "                        dtype=np.uint8)\n",
    "\n",
    "        for i, p in enumerate(info[\"polygons\"]):\n",
    "            # Get indexes of pixels inside the polygon and set them to 1\n",
    "            rr, cc = skimage.draw.polygon(p['all_points_y'], p['all_points_x'])\n",
    "            mask[rr, cc, i] = 1\n",
    "        # print(\"info['num_ids']=\", info['num_ids'])\n",
    "        # Map class names to class IDs.\n",
    "        num_ids = np.array(num_ids, dtype=np.int32)\n",
    "        return mask, num_ids\n",
    "    \n",
    "        \n",
    "    def image_reference(self, image_id):\n",
    "        \"\"\"Return the path of the image.\n",
    "        info = self.image_info[image_id]\n",
    "        if info[\"source\"] == \"raspberry\":\n",
    "            return info[\"path\"]\n",
    "        else:\n",
    "            super(self.__class__, self).image_reference(image_id)\"\"\"\n",
    "       \n",
    "        \"\"\"Return the path of the image.\"\"\"\n",
    "        info = self.image_info[image_id]\n",
    "        if info[\"source\"] == \"object\":\n",
    "            return info[\"path\"]\n",
    "        else:\n",
    "            super(self.__class__, self).image_reference(image_id)\n",
    "\n",
    "\n",
    "############################################################\n",
    "#  COCO Evaluation\n",
    "############################################################\n",
    "\n",
    "def build_raspberry_results(dataset, image_ids, rois, class_ids, scores, masks):\n",
    "    \"\"\"Arrange resutls to match COCO specs in http://cocodataset.org/#format\n",
    "    \"\"\"\n",
    "    # If no results, return an empty list\n",
    "    if rois is None:\n",
    "        return []\n",
    "    \n",
    "\n",
    "    results = []\n",
    "    for image_id in image_ids:\n",
    "        # Loop through detections\n",
    "        for i in range(rois.shape[0]):\n",
    "            class_id = class_ids[i]\n",
    "            score = scores[i]\n",
    "            bbox = np.around(rois[i], 1)\n",
    "            mask = masks[:, :, i]\n",
    "\n",
    "            result = {\n",
    "                \"image_id\": image_id,\n",
    "                \"category_id\": dataset.get_source_class_id(class_id, \"object\"),\n",
    "                \"bbox\": [bbox[1], bbox[0], bbox[3] - bbox[1], bbox[2] - bbox[0]],\n",
    "                \"score\": score,\n",
    "                \"segmentation\": maskUtils.encode(np.asfortranarray(mask))\n",
    "            }\n",
    "            results.append(result)\n",
    "    #print(\"should have results to load now\")\n",
    "    return results\n",
    "\n",
    "\n",
    "def evaluate_raspberry(model, dataset, annotations, eval_type=\"segm\", limit=100, image_ids=None):\n",
    "    \n",
    "    # Compute VOC-Style mAP @ IoU=0.5\n",
    "    # Running on 10 images. Increase for better accuracy.\n",
    "    inference_config = RaspberryConfig()\n",
    "    image_ids = np.random.choice(dataset_val.image_ids, limit)\n",
    "    APs = []\n",
    "    for image_id in image_ids:\n",
    "        # Load image and ground truth data\n",
    "        image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
    "            modellib.load_image_gt(dataset_val, inference_config,\n",
    "                                   image_id, use_mini_mask=False)\n",
    "        molded_images = np.expand_dims(modellib.mold_image(image, inference_config), 0)\n",
    "        # Run object detection\n",
    "        results = model.detect([image], verbose=0)\n",
    "        r = results[0]\n",
    "        # Compute AP\n",
    "        \"\"\"AP, precisions, recalls, overlaps =\\\n",
    "            utils.compute_ap(gt_bbox, gt_class_id, gt_mask,\n",
    "                             r[\"rois\"], r[\"class_ids\"], r[\"scores\"], r['masks'])\"\"\"\n",
    "        AP = utils.compute_ap_range(gt_bbox, gt_class_id, gt_mask, r[\"rois\"], r[\"class_ids\"], r[\"scores\"], r['masks'])\n",
    "        APs.append(AP)\n",
    "    \n",
    "    #print(str(APs))\n",
    "    print(\"mAP: \", np.mean(APs))\n",
    "    mAP=np.mean(APs)\n",
    "    average.append(mAP)\n",
    "    mAP=str(mAP)\n",
    "    f.write(\"%s, \" % mAP)\n",
    "    print(\"evaluation completed and recorded\")\n",
    "\n",
    "\n",
    "############################################################\n",
    "#  Training\n",
    "############################################################\n",
    "\n",
    "\n",
    "def run(dataset, model):\n",
    "    import argparse\n",
    "\n",
    "    \n",
    "\n",
    "    class InferenceConfig(RaspberryConfig):\n",
    "        # Set batch size to 1 since we'll be running inference on\n",
    "        # one image at a time. Batch size = GPU_COUNT * IMAGES_PER_GPU\n",
    "        GPU_COUNT = 1\n",
    "        IMAGES_PER_GPU = 1\n",
    "        DETECTION_MIN_CONFIDENCE = 0\n",
    "    config = InferenceConfig()\n",
    "    config.display()\n",
    "\n",
    "    model = modellib.MaskRCNN(mode=\"inference\", config=config,\n",
    "                                  model_dir=logs)\n",
    "\n",
    "    \n",
    "    model_path = model\n",
    "\n",
    "    # Load weights\n",
    "    print(\"Loading weights \", model_path)\n",
    "    model.load_weights(model_path, by_name=True)\n",
    "\n",
    "    # Train or evaluate\n",
    "    if args.command == \"train\":\n",
    "        \n",
    "        print(\"Training network heads\")\n",
    "        \n",
    "\n",
    "    elif args.command == \"evaluate\":\n",
    "        # Validation dataset\n",
    "        dataset_val = RaspberryDataset()\n",
    "        raspberry = dataset_val.load_raspberry(dataset, \"test\")\n",
    "        dataset_val.prepare()\n",
    "        average=[]\n",
    "        f.write(\"Model = %s ,mAP, \" % model_path)\n",
    "        print(\"Running RASP evaluation on 100 images.\")\n",
    "        evaluate_raspberry(model, dataset_val, raspberry, \"segm\", limit=100)\n",
    "        evaluate_raspberry(model, dataset_val, raspberry, \"segm\", limit=100)\n",
    "        evaluate_raspberry(model, dataset_val, raspberry, \"segm\", limit=100)\n",
    "        evaluate_raspberry(model, dataset_val, raspberry, \"segm\", limit=100)\n",
    "        evaluate_raspberry(model, dataset_val, raspberry, \"segm\", limit=100)\n",
    "        evaluate_raspberry(model, dataset_val, raspberry, \"segm\", limit=100)\n",
    "        evaluate_raspberry(model, dataset_val, raspberry, \"segm\", limit=100)\n",
    "        evaluate_raspberry(model, dataset_val, raspberry, \"segm\", limit=100)\n",
    "        evaluate_raspberry(model, dataset_val, raspberry, \"segm\", limit=100)\n",
    "        evaluate_raspberry(model, dataset_val, raspberry, \"segm\", limit=100)\n",
    "\n",
    "        average=str(np.mean(average))\n",
    "        f.write(\"Mean, %s, \\n\" % average)\n",
    "        f.close()\n",
    "    else:\n",
    "        print(\" is not recognized. \"\n",
    "              \"Use 'train' or 'evaluate'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'required' is an invalid argument for positionals",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-cea93a93f329>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'/host/Mask_RCNN/datasets/raspberry/'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'/host/Mask_RCNN/logs/raspberry20180823T2131/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-11-f4c1edf96709>\u001b[0m in \u001b[0;36mrun\u001b[0;34m(dataset, model)\u001b[0m\n\u001b[1;32m    343\u001b[0m     parser.add_argument(\"command\", required=False, default='evaluate',\n\u001b[1;32m    344\u001b[0m                         \u001b[0mmetavar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"<command>\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m                         help=\"'train' or 'evaluate' on MS COCO\")\n\u001b[0m\u001b[1;32m    346\u001b[0m     parser.add_argument('--dataset', required=False, default=dataset,\n\u001b[1;32m    347\u001b[0m                         \u001b[0mmetavar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"/path/to/coco/\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/argparse.py\u001b[0m in \u001b[0;36madd_argument\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1319\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m'dest'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dest supplied twice for positional argument'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1321\u001b[0;31m             \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_positional_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m         \u001b[0;31m# otherwise, we're adding an optional argument\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/argparse.py\u001b[0m in \u001b[0;36m_get_positional_kwargs\u001b[0;34m(self, dest, **kwargs)\u001b[0m\n\u001b[1;32m   1431\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'required'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1432\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"'required' is an invalid argument for positionals\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1433\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1435\u001b[0m         \u001b[0;31m# mark positional arguments as required if at least one is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'required' is an invalid argument for positionals"
     ]
    }
   ],
   "source": [
    "run(dataset='/host/Mask_RCNN/datasets/raspberry/', model='/host/Mask_RCNN/logs/raspberry20180823T2131/') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook Preferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Validation Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
